{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXS14MDqjAdS"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y-NMgMlIa-_"
      },
      "source": [
        "# Auto-sklearn\n",
        "Auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.\n",
        "\n",
        "For more information about the framework, please visit the documentation [here](https://automl.github.io/auto-sklearn/master/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ihaCc5KtFL"
      },
      "source": [
        "## What you will need to run the code\n",
        "\n",
        "In order to run this code, we are going to first install Auto-sklearn using pip. For more instructions on how to install Auto-sklearn, for example using conda, please check [this](https://automl.github.io/auto-sklearn/master/installation.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.8.1\n",
        "# restart kernel!"
      ],
      "metadata": {
        "id": "Tsa70kzEts-f",
        "outputId": "59cd5552-d6e3-48be-d17c-280aaa6443f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.8.1 in /usr/local/lib/python3.10/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scipy==1.8.1) (1.24.4)\n",
            "Collecting Cython==0.29.35\n",
            "  Downloading Cython-0.29.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Cython\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.10\n",
            "    Uninstalling Cython-3.0.10:\n",
            "      Successfully uninstalled Cython-3.0.10\n",
            "Successfully installed Cython-0.29.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Cython==0.29.35"
      ],
      "metadata": {
        "id": "qVYEPyPOFR06",
        "outputId": "a8933658-e293-4ce1-d1ff-76791e80eb38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Cython==0.29.35 in /usr/local/lib/python3.10/dist-packages (0.29.35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==0.24.2 --no-build-isolation"
      ],
      "metadata": {
        "id": "JFyjyyRPgqnc",
        "outputId": "1df2db49-f1b8-42c1-ef63-c2fc59a9620c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.24.2\n",
            "  Using cached scikit-learn-0.24.2.tar.gz (7.5 MB)\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.24.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (3.5.0)\n",
            "Building wheels for collected packages: scikit-learn\n",
            "  Building wheel for scikit-learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-learn: filename=scikit_learn-0.24.2-cp310-cp310-linux_x86_64.whl size=22196226 sha256=a2624ce429b05bf41f9182aea8fb220a8bc153478103c607c9b71478e30c634d\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/a4/68/4e78865652fa14db4a162b491e5138565f97646f9e1f2ab8cc\n",
            "Successfully built scikit-learn\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.4.0 requires scikit-learn>=1.2.2, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "imbalanced-learn 0.10.1 requires scikit-learn>=1.0.2, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "mlxtend 0.22.0 requires scikit-learn>=1.0.2, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-0.24.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              },
              "id": "ec7b9898fb614eb5bdb313a6aee122ff"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWhGa_OANAMM",
        "outputId": "4c226622-8750-4b89-a214-1a8ad1233401"
      },
      "source": [
        "#this needs to run twice!\n",
        "!pip install auto-sklearn\n",
        "import autosklearn\n",
        "\n",
        "print(\"Using Auto-sklearn version {}\".format(autosklearn.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting auto-sklearn\n",
            "  Downloading auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (4.11.0)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (1.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (1.4.0)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Requirement already satisfied: dask>=2021.12 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (2023.8.1)\n",
            "Requirement already satisfied: distributed>=2012.12 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (2023.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (6.0.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (2.0.3)\n",
            "Collecting liac-arff (from auto-sklearn)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from auto-sklearn) (3.5.0)\n",
            "Collecting ConfigSpace<0.5,>=0.4.21 (from auto-sklearn)\n",
            "  Downloading ConfigSpace-0.4.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynisher<0.7,>=0.6.3 (from auto-sklearn)\n",
            "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyrfr<0.9,>=0.8.1 (from auto-sklearn)\n",
            "  Downloading pyrfr-0.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smac<1.3,>=1.2 (from auto-sklearn)\n",
            "  Downloading smac-1.2.tar.gz (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (0.29.35)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (3.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (24.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (1.4.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.12->auto-sklearn) (7.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (3.1.3)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (2.0.7)\n",
            "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2012.12->auto-sklearn) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->auto-sklearn) (2024.1)\n",
            "Collecting emcee>=3.0.0 (from smac<1.3,>=1.2->auto-sklearn)\n",
            "  Downloading emcee-3.1.6-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2021.12->auto-sklearn) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2012.12->auto-sklearn) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->auto-sklearn) (1.16.0)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher, smac, liac-arff\n",
            "  Building wheel for auto-sklearn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.15.0-py3-none-any.whl size=6641936 sha256=8cfd2517a8c27aee7054869aba62aebe4f7095e283d70475b1ab79a74d702984\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/0a/f9/8c1a06bcc36bc16b467b044b5bb03a90f92a5c5e6cd443414b\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7026 sha256=59129050e2e0f4aefa6490362a77ad687973826b187e5c555d02ef87c4206dca\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/7b/53/b21d6b41910f43c7f1557262e579598f83e75e44c659c1bcce\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-1.2-py3-none-any.whl size=215906 sha256=a1099d565dc027ff8019f484141e20975bf2b2d13ce1eb4e58e6517cdfc49b42\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/2e/d9/2db14bdfcdc36bf12e202b44201df03f194367fcfd85ce2778\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=ff608746292f3ebda8342f7236e325b3fc9e0d62d5d2badcb8211af77354e5b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built auto-sklearn pynisher smac liac-arff\n",
            "Installing collected packages: pyrfr, pynisher, liac-arff, emcee, ConfigSpace, smac, auto-sklearn\n",
            "Successfully installed ConfigSpace-0.4.21 auto-sklearn-0.15.0 emcee-3.1.6 liac-arff-2.5.0 pynisher-0.6.4 pyrfr-0.8.3 smac-1.2\n",
            "Using Auto-sklearn version 0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUxbg5B2J8lU"
      },
      "source": [
        "## First Step: Load data\n",
        "\n",
        "Auto-sklearn can work with multiple input data formats (python lists, numpy arrays, sparse arrays and pandas data-frames).  \n",
        "\n",
        "For this example we are going to be using the [credit-g dataset](https://www.openml.org/d/31) which is a binary classification problem. This means that we have to find an estimator that is able to predict between 2 categories, *'bad'* and *'good'*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxGRtUSmJ7ki",
        "outputId": "954c50f1-a24d-4aba-bb3c-0f6d42702a39"
      },
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.model_selection\n",
        "\n",
        "# We fetch the data using the openml.org\n",
        "X, y = sklearn.datasets.fetch_openml(data_id=31, return_X_y=True, as_frame=True)\n",
        "\n",
        "# Split the data into train and test\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "X_train.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 600 entries, 24 to 102\n",
            "Data columns (total 20 columns):\n",
            " #   Column                  Non-Null Count  Dtype   \n",
            "---  ------                  --------------  -----   \n",
            " 0   checking_status         600 non-null    category\n",
            " 1   duration                600 non-null    float64 \n",
            " 2   credit_history          600 non-null    category\n",
            " 3   purpose                 600 non-null    category\n",
            " 4   credit_amount           600 non-null    float64 \n",
            " 5   savings_status          600 non-null    category\n",
            " 6   employment              600 non-null    category\n",
            " 7   installment_commitment  600 non-null    float64 \n",
            " 8   personal_status         600 non-null    category\n",
            " 9   other_parties           600 non-null    category\n",
            " 10  residence_since         600 non-null    float64 \n",
            " 11  property_magnitude      600 non-null    category\n",
            " 12  age                     600 non-null    float64 \n",
            " 13  other_payment_plans     600 non-null    category\n",
            " 14  housing                 600 non-null    category\n",
            " 15  existing_credits        600 non-null    float64 \n",
            " 16  job                     600 non-null    category\n",
            " 17  num_dependents          600 non-null    float64 \n",
            " 18  own_telephone           600 non-null    category\n",
            " 19  foreign_worker          600 non-null    category\n",
            "dtypes: category(13), float64(7)\n",
            "memory usage: 47.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovb0DEDfTRz1"
      },
      "source": [
        "## Second Step: Manually build a pipeline\n",
        "\n",
        "For this tutorial, we are going to implement some traditional machine learning models ([GradientBoosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html), [Decision Tree Classifier](https://scikit-learn.org/stable/modules/tree.html)) using [scikit-learn](https://scikit-learn.org/stable/index.html). Then we are going to show how we can achieve an even better performance than these traditional models, by using Auto-Sklearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx8gyRP0cL_N"
      },
      "source": [
        "### C-Support Vector Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkhGLtCCT0i6",
        "outputId": "945bf632-12fe-4691-96e8-d47e45e6a3e7"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# Create the estimator using the default parameters from the library\n",
        "estimator_svc = SVC(\n",
        "    C=1.0, kernel='rbf', gamma='scale', shrinking=True, tol=1e-3,\n",
        "    cache_size=200, verbose=False, max_iter=-1, random_state=42\n",
        ")\n",
        "\n",
        "# build and fit the pipeline\n",
        "categorical_columns = [col for col in X_train.columns\n",
        "                       if X[col].dtype.name == 'category']\n",
        "encoder = ColumnTransformer(transformers = [\n",
        "  ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
        "], remainder='passthrough')\n",
        "pipeline_svc = Pipeline([\n",
        "  ('encoder', encoder),\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('svc', estimator_svc),\n",
        "])\n",
        "pipeline_svc.fit(X_train, y_train)\n",
        "\n",
        "# Score the model\n",
        "prediction = pipeline_svc.predict(X_test)\n",
        "performance_svc = accuracy_score(y_test, prediction)\n",
        "print(f\"SVC performance is {performance_svc}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC performance is 0.7675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzcQy2lFnUVY"
      },
      "source": [
        "### GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmWaffHyTRCp",
        "outputId": "06bf6cbd-27f2-4b59-9297-fdac2a20e063"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Create the estimator using default parameters from the library\n",
        "estimator_gradboost = GradientBoostingClassifier(\n",
        "    learning_rate=0.1, n_estimators=100, subsample=1.0,\n",
        "    criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1,\n",
        "    min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
        "    random_state=42)\n",
        "\n",
        "# Translate the categorical columns to\n",
        "# a numerical value\n",
        "categorical_columns = [col for col in X_train.columns\n",
        "                       if X[col].dtype.name == 'category']\n",
        "encoder = ColumnTransformer(transformers = [\n",
        "  ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
        "], remainder='passthrough')\n",
        "\n",
        "\n",
        "# Build and fit the pipeline\n",
        "pipeline_gradboost = Pipeline([\n",
        "  ('encoder', encoder),\n",
        "  ('gradboost', estimator_gradboost),\n",
        "])\n",
        "pipeline_gradboost.fit(X_train, y_train)\n",
        "\n",
        "# Score the model\n",
        "prediction = pipeline_gradboost.predict(X_test)\n",
        "performance_gradboost = accuracy_score(y_test, prediction)\n",
        "print(f\"GradientBooster performance is {performance_gradboost}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBooster performance is 0.735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur1jyA7Ncc8M"
      },
      "source": [
        "### Decision tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE_s9S3Pef0E",
        "outputId": "8336ca65-8098-40c5-a7e5-5205a26a3ae5"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the estimator using the default parameters from the library\n",
        "estimator_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# build and fit the pipeline\n",
        "encoder = ColumnTransformer(transformers = [\n",
        "  ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
        "], remainder='passthrough')\n",
        "pipeline_tree = Pipeline([\n",
        "  ('encoder', encoder),\n",
        "  ('DecisionTree', estimator_tree),\n",
        "])\n",
        "pipeline_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training data\n",
        "prediction = pipeline_tree.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "performance_tree = accuracy_score(y_test, prediction)\n",
        "print(f\"Decision Tree performance is {performance_tree}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree performance is 0.7075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjIrVVFCf7PP"
      },
      "source": [
        "# Third Step: Use Auto-sklearn as a drop-in-replacement\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6a9W6xef7bI",
        "outputId": "1109e12b-9270-4ffc-8f40-974e1008aa77"
      },
      "source": [
        "import autosklearn.classification\n",
        "\n",
        "# Create and train the estimator\n",
        "estimator_askl = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=300,\n",
        "    seed=42,\n",
        "    resampling_strategy='cv',\n",
        "    n_jobs=1,\n",
        ")\n",
        "estimator_askl.fit(X_train, y_train)\n",
        "\n",
        "# Score the model\n",
        "prediction = estimator_askl.predict(X_test)\n",
        "performance_askl = accuracy_score(y_test, prediction)\n",
        "print(f\"Auto-Sklearn Classifier performance is {performance_askl}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autosklearn/data/target_validator.py:187: UserWarning: Fitting transformer with a pandas series which has the dtype category. Inverse transform may not be able preserve dtype when converting to np.ndarray\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-Sklearn Classifier performance is 0.785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQojc2E6jIWA",
        "outputId": "3f7a3e8e-27c8-491b-ff4b-9eb07f570246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import data_table\n",
        "\n",
        "# By using Auto-Sklearn on can achieve a better performance!\n",
        "data_table.DataTable(\n",
        "pd.DataFrame(\n",
        "    [\n",
        "     {'Model': 'Auto-Sklearn Classifier', 'Accuracy': performance_askl},\n",
        "     {'Model': 'GradientBoosting', 'Accuracy': performance_gradboost},\n",
        "     {'Model': 'Decision Tree Classifier', 'Accuracy': performance_tree},\n",
        "     {'Model': 'Support Vector Classifier', 'Accuracy': performance_svc},\n",
        "     ]\n",
        "))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Auto-Sklearn Classifier</td>\n",
              "      <td>0.7850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>0.7350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Support Vector Classifier</td>\n",
              "      <td>0.7675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/881c4a0d49046431/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Auto-Sklearn Classifier\",\n{\n            'v': 0.785,\n            'f': \"0.785\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"GradientBoosting\",\n{\n            'v': 0.735,\n            'f': \"0.735\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"Decision Tree Classifier\",\n{\n            'v': 0.7075,\n            'f': \"0.7075\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"Support Vector Classifier\",\n{\n            'v': 0.7675,\n            'f': \"0.7675\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Model\"], [\"number\", \"Accuracy\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-4a88aad0-5c8a-44ad-8349-793b9fb7f21f\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a88aad0-5c8a-44ad-8349-793b9fb7f21f')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-4a88aad0-5c8a-44ad-8349-793b9fb7f21f button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "* Setup MLFlow (see [Week 3](https://colab.research.google.com/github/keuperj/MLSystems24/blob/main/week_3/MLFlow_Tutorial.ipynb) ) and tack the different hyper-parameter runs in the example above\n",
        "* generate plots to find the best model and hyperparameters"
      ],
      "metadata": {
        "id": "BJtK9BxI-hIV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PbZd522q-_to"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}